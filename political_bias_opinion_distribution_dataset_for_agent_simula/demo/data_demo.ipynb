{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Political Bias Opinion Distribution Dataset\n",
    "\n",
    "This notebook demonstrates working with the **cajcodes/political-bias** dataset, which provides a 5-point political bias scale ideal for agent-based opinion dynamics simulations.\n",
    "\n",
    "## Dataset Overview\n",
    "- **Source**: cajcodes/political-bias\n",
    "- **Scale**: 5-point (0=far_right to 4=far_left)\n",
    "- **Normalized Scale**: -1.0 to +1.0 (right to left)\n",
    "- **Use Case**: Opinion dynamics, agent-based modeling, political bias classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport urllib.request\nimport os\n\n# Configuration\nGITHUB_RAW_URL = \"https://raw.githubusercontent.com/AMGrobelnik/ai-invention-ab58ab-perception-asymmetry-feedback-loop-how-d/main/political_bias_opinion_distribution_dataset_for_agent_simula/demo/demo_data.json\"\nLOCAL_FILE = \"demo_data.json\"\n\ndef load_data():\n    \"\"\"Load data from GitHub URL (for Colab) or local file (for local development).\"\"\"\n    # Try GitHub URL first (works in Colab)\n    try:\n        print(f\"Attempting to load from GitHub: {GITHUB_RAW_URL}\")\n        with urllib.request.urlopen(GITHUB_RAW_URL) as response:\n            print(\"Successfully loaded from GitHub\")\n            return json.loads(response.read().decode(\"utf-8\"))\n    except Exception as e:\n        print(f\"GitHub fetch failed: {e}\")\n    \n    # Fallback to local file\n    if os.path.exists(LOCAL_FILE):\n        print(f\"Loading from local file: {LOCAL_FILE}\")\n        with open(LOCAL_FILE, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    \n    raise FileNotFoundError(\"Could not load data from GitHub or local file\")\n\n# Load the dataset\ndata = load_data()\nexamples = data[\"examples\"]\nprint(f\"Loaded {len(examples)} examples\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore the Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the structure of a single example\n",
    "example = examples[0]\n",
    "print(\"Example structure:\")\n",
    "print(json.dumps(example, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key fields for analysis\n",
    "for i, ex in enumerate(examples[:5]):\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    print(f\"Bias Category: {ex['context']['bias_category']}\")\n",
    "    print(f\"Opinion Score: {ex['context']['opinion_score']}\")\n",
    "    # Extract the statement from the input\n",
    "    statement = ex['input'].split('\"')[1]\n",
    "    print(f\"Statement: {statement[:80]}...\" if len(statement) > 80 else f\"Statement: {statement}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Opinion Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count examples by bias category\n",
    "categories = [ex[\"context\"][\"bias_category\"] for ex in examples]\n",
    "category_counts = Counter(categories)\n",
    "\n",
    "print(\"Distribution by Bias Category:\")\n",
    "print(\"=\" * 40)\n",
    "# Order from far_right to far_left\n",
    "order = [\"far_right\", \"right\", \"center\", \"left\", \"far_left\"]\n",
    "for cat in order:\n",
    "    count = category_counts.get(cat, 0)\n",
    "    bar = \"█\" * count\n",
    "    print(f\"{cat:12} | {bar} ({count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract opinion scores for numerical analysis\n",
    "opinion_scores = [ex[\"context\"][\"opinion_score\"] for ex in examples]\n",
    "\n",
    "print(\"Opinion Score Statistics:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Min:  {min(opinion_scores)}\")\n",
    "print(f\"Max:  {max(opinion_scores)}\")\n",
    "print(f\"Mean: {sum(opinion_scores) / len(opinion_scores):.2f}\")\n",
    "print(f\"\\nScore mapping:\")\n",
    "print(\"  -1.0 = far_right\")\n",
    "print(\"  -0.5 = right\")\n",
    "print(\"   0.0 = center\")\n",
    "print(\"   0.5 = left\")\n",
    "print(\"   1.0 = far_left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Data for Agent-Based Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statement(input_text):\n",
    "    \"\"\"Extract the statement from the classification input.\"\"\"\n",
    "    try:\n",
    "        return input_text.split('\"')[1]\n",
    "    except IndexError:\n",
    "        return input_text\n",
    "\n",
    "# Create a simplified dataset for agent simulations\n",
    "agent_data = []\n",
    "for ex in examples:\n",
    "    agent_data.append({\n",
    "        \"statement\": extract_statement(ex[\"input\"]),\n",
    "        \"opinion_score\": ex[\"context\"][\"opinion_score\"],\n",
    "        \"bias_category\": ex[\"context\"][\"bias_category\"]\n",
    "    })\n",
    "\n",
    "print(\"Agent-ready data format:\")\n",
    "print(json.dumps(agent_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group statements by opinion score for simulation scenarios\n",
    "by_opinion = {}\n",
    "for item in agent_data:\n",
    "    score = item[\"opinion_score\"]\n",
    "    if score not in by_opinion:\n",
    "        by_opinion[score] = []\n",
    "    by_opinion[score].append(item[\"statement\"])\n",
    "\n",
    "print(\"Statements grouped by opinion score:\")\n",
    "print(\"=\" * 50)\n",
    "for score in sorted(by_opinion.keys()):\n",
    "    statements = by_opinion[score]\n",
    "    print(f\"\\nScore {score:+.1f} ({len(statements)} statements):\")\n",
    "    for stmt in statements[:2]:  # Show first 2\n",
    "        print(f\"  • {stmt[:60]}...\" if len(stmt) > 60 else f\"  • {stmt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Create histogram of opinion scores\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # Plot histogram\n",
    "    ax.hist(opinion_scores, bins=5, range=(-1.25, 1.25), \n",
    "            color='steelblue', edgecolor='white', alpha=0.8)\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xlabel('Opinion Score', fontsize=12)\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "    ax.set_title('Distribution of Political Opinion Scores', fontsize=14)\n",
    "    ax.set_xticks([-1.0, -0.5, 0.0, 0.5, 1.0])\n",
    "    ax.set_xticklabels(['Far Right\\n(-1.0)', 'Right\\n(-0.5)', 'Center\\n(0.0)', \n",
    "                       'Left\\n(0.5)', 'Far Left\\n(1.0)'])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"matplotlib not available. Install with: pip install matplotlib\")\n",
    "    print(\"Skipping visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This dataset provides:\n",
    "- **15 diverse examples** spanning the full political spectrum\n",
    "- **5-point scale** from far_right (-1.0) to far_left (+1.0)\n",
    "- **Ready-to-use format** for opinion dynamics simulations\n",
    "- **Structured context** with bias category and normalized scores\n",
    "\n",
    "### Use Cases\n",
    "1. **Agent-Based Modeling**: Use opinion scores to initialize agent beliefs\n",
    "2. **Polarization Studies**: Analyze how extreme vs. moderate opinions interact\n",
    "3. **Feedback Loop Analysis**: Study perception asymmetry in political discourse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}